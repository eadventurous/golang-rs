//! # EBNF syntax parser and converter

use lang::ebnf::*;
use lex::MetaResult;

#[derive(Clone, Debug)]
pub struct Syntax {
    rules: Vec<Rule>,
    autogenerated_names_registry: Vec<String>,
}

#[derive(Clone, Debug, Eq, PartialEq)]
pub struct Rule {
    name: String,
    definitions: DefinitionList,
}

#[derive(Clone, Debug, Eq, PartialEq)]
pub struct DefinitionList(pub Vec<Definition>);

/// Syntactic definitions are separated by one of '|', '/', '!'.
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct Definition(pub Vec<Primary>);

pub type Alternative = Definition;

/// Syntactic terms are separated by comma ','.
#[derive(Clone, Debug, Eq, PartialEq)]
pub enum Primary {
    Optional(DefinitionList),
    Repeated(DefinitionList),
    Grouped(DefinitionList),
    Terminal(String),
    NonTerminal(String),
    Epsilon,
}

/// To be a little bit more consistent with ISO standard on EBNF.
pub type Term = Primary;
pub type Factor = Primary;

#[derive(Clone, Debug, Eq, PartialEq)]
pub enum Nesting {
    Optional,
    Repeated,
    Grouped,
}

/// Recursion kind for a syntax rule definition.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub enum Recursion {
    /// Left-recursive.
    Left,
    /// Right-recursive.
    Right,
}

type EbnfTokens<'a> = ::lex::Tokens<'a, EbnfToken<'a>>;

pub struct Parser<'a> {
    /// Source text
    source: &'a str,
    /// Current token.
    t: Option<MetaResult<'a, EbnfToken<'a>>>,
    /// Iterator over tokens stream.
    iter: EbnfTokens<'a>,
}

mod impls {
    use super::super::bnf;
    use super::*;
    use lex::{ErrorBytes, MetaResult, SimpleErrorBytes, Span, Token, TokenMeta};
    use std::fmt::{self, Display, Formatter};
    use std::ops::{Deref, DerefMut};
    use syn::bnf::non_empties;

    impl Syntax {
        pub fn new() -> Self {
            Self {
                rules: Vec::new(),
                autogenerated_names_registry: Vec::new(),
            }
        }

        /// 2-in-1: `expand_ebnf` and `into_bnf` working together.
        pub fn ebnf_to_bnf(&mut self, recursion: Recursion) -> bnf::Grammar {
            self.expand_ebnf(recursion);
            self.into_bnf().unwrap()
        }

        /// EBNF to BNF transformation.
        ///
        /// This process eliminates each nesting term according to three rules: see `rule_1`,
        /// `rule_2` and `rule_3` for more information. Those rules are not means to be called
        /// directly, but rather made public for educational purposes. Use `find_nesting` function
        /// to fetch parameters for them.
        pub fn expand_ebnf(&mut self, recursion: Recursion) {
            while let Some(xyz) = self.find_nested() {
                let ref nesting = self.extract(xyz).nesting();
                match nesting {
                    Some(Nesting::Repeated) => {
                        self.rule_1(xyz, recursion);
                    }
                    Some(Nesting::Optional) => {
                        self.rule_2(xyz);
                    }
                    Some(Nesting::Grouped) => {
                        self.rule_3(xyz);
                    }
                    _ => unreachable!(),
                }
            }
        }

        /// Downgrade EBNF syntax to BNF.
        ///
        /// This does not try to rewrite existing rules to eliminate nesting.
        /// To do that, `expand_ebnf` first.
        pub fn into_bnf(&self) -> Result<bnf::Grammar, ()> {
            let mut bnf = bnf::Grammar::new();

            for rule in &self.rules {
                bnf.rules.push(rule.into_bnf()?);
            }

            Ok(bnf)
        }

        /// 1. Convert every repetition `{ E }` to a fresh non-terminal `X` and add `X = eps | X ( E )`.
        pub fn rule_1(&mut self, (x, y, z): (usize, usize, usize), recursion: Recursion) {
            #![allow(non_snake_case)]
            match self.extract((x, y, z)).nesting() {
                Some(Nesting::Repeated) => {
                    let X_index = self.add_rule();

                    // wait for rust [nll] feature
                    let list = {
                        let mut X = self.rules[X_index].non_terminal();

                        // nesting = { E }
                        let nesting = self.extract_mut((x, y, z));

                        // swap X and { E }
                        ::std::mem::swap(&mut X, nesting);
                        // clean up after swapping pointers
                        let (X, mut E) = (nesting.clone(), X.into_inner().unwrap());

                        // X = eps | X E
                        DefinitionList(vec![
                            // eps
                            Definition(vec![Primary::Epsilon]),
                            // X E
                            Definition({
                                if E.len() == 1 {
                                    // reuse E
                                    let mut def = E.0.into_iter().nth(0).unwrap().0;
                                    match recursion {
                                        Recursion::Left => {
                                            def.insert(0, X);
                                        }
                                        Recursion::Right => {
                                            def.push(X);
                                        }
                                    }
                                    def
                                } else {
                                    match recursion {
                                        Recursion::Left => vec![X, Primary::Grouped(E)],
                                        Recursion::Right => vec![Primary::Grouped(E), X],
                                    }
                                }
                            }),
                        ])
                    };

                    // add rule X
                    self.rules[X_index].definitions = list;
                }
                _ => unreachable!(),
            }
        }

        /// 2. Convert every option `[ E ]` to a fresh non-terminal `X` and add `X = eps | E`.
        /// (We can convert `X = A [ E ] B` to `X = A E B | A B`.)
        pub fn rule_2(&mut self, (x, y, z): (usize, usize, usize)) {
            #![allow(non_snake_case)]
            match self.extract((x, y, z)).nesting() {
                Some(Nesting::Optional) => {
                    // Convert `X = A [ E ] B` to `X = A E B | A B`.
                    // Note that definitions list of X may contain other alternatives on both sides of
                    // definition containing optional term. For example:
                    // X = I | A [ E ]  B  | ( J | K ) | { L }
                    // X = I | A E B | A B | ( J | K ) | { L }
                    // In such case, expansion must take care of preserving other context.

                    // Expand `A [ E ] B` to `A E B`.
                    // Consider cases where E introduces new "alternatives scope" (e.g. E ::= A | B)
                    // as well as where E is defined as single `Definition`.

                    // this is not actually E, but surrounding Primary::Optional [ E ]
                    let E_outer = self.rules[x].definitions[y].remove(z);
                    let mut E = E_outer.into_inner().unwrap();

                    if E.is_empty() {
                        // just remove it.
                        // nothing more to do.
                    } else if E.len() == 1 {
                        // insert alternative with and without E back to the definitions

                        // without E
                        // - already done by removing

                        // with expanded E
                        // - optional of single definition (i.e. not a list of alternatives):
                        //   `[ E ]` or `[ A B { C } ]`
                        let inners = E.0.into_iter().nth(0).unwrap();

                        // inflate current alternate definition
                        let mut definition = self.rules[x].definitions[y].clone();
                        definition.splice(z..z, inners.0);
                        self.rules[x].definitions.insert(y, definition);
                    } else {
                        // multiple definitions (i.e. a list of alternatives):
                        // `[ A | B ]`

                        // Convert to fresh non-terminal `X` and add `X = eps | E`.
                        let X_index = self.add_rule();

                        // prepend eps | E
                        E.0.insert(0, Definition(vec![Primary::Epsilon]));
                        // set `X = eps | E`
                        self.rules[X_index].definitions = E;

                        // replace [E] with X
                        let X = self.rules[X_index].non_terminal();
                        self.rules[x].definitions[y].insert(z, X.clone());
                    }
                }
                _ => unreachable!(),
            }
        }

        /// 3. Convert every group `( E )` to a fresh non-terminal `X` and add `X = E`.
        pub fn rule_3(&mut self, (x, y, z): (usize, usize, usize)) {
            #![allow(non_snake_case)]
            match self.extract((x, y, z)).nesting() {
                Some(Nesting::Grouped) => {
                    let E_outer = self.rules[x].definitions[y].remove(z);
                    let mut E = E_outer.into_inner().unwrap();

                    if E.is_empty() {
                        // for empty ( ) just remove it
                        // nothing more to do
                    } else {
                        let X_index = self.add_rule();
                        self.rules[X_index].definitions = E;

                        // insert X in place of removed ( E )
                        let mut X = self.rules[X_index].non_terminal();
                        self.rules[x].definitions[y].insert(z, X);
                    }
                }
                _ => unreachable!(),
            }
        }

        /// Shortcut for `self->rules[x]->definitions[y]->primaries[z]`. Immutable version.
        fn extract(&self, (x, y, z): (usize, usize, usize)) -> &Primary {
            &self.rules[x].definitions[y][z]
        }

        /// Shortcut for `self->rules[x]->definitions[y]->primaries[z]`. Mutable version.
        fn extract_mut(&mut self, (x, y, z): (usize, usize, usize)) -> &mut Primary {
            &mut self.rules[x].definitions[y][z]
        }

        /// Create new empty rule with auto-generated name and return its index in `self.rules`
        /// vector.
        fn add_rule(&mut self) -> usize {
            let rule: Rule = Rule::new(self.allocate_new_name(), DefinitionList(vec![]));
            self.rules.push(rule);
            self.rules.len() - 1
        }

        /// Generate new name in format `X-auto-{serial number}` and save it to the registry.
        ///
        /// # Returns
        ///
        /// Reference to newly generated name in the registry.
        fn allocate_new_name(&mut self) -> &str {
            let name = format!("X-auto-{}", self.autogenerated_names_registry.len());
            self.autogenerated_names_registry.push(name);
            &*self.autogenerated_names_registry.last().unwrap()
        }

        /// Find next nearest nested term, top-down, left-to-right. Result of this function should
        /// be used as an argument to one of the `rule_{1,2,3}` functions.
        ///
        /// # Returns
        ///
        /// Three indices: rule, definition, primary.
        fn find_nested(&self) -> Option<(usize, usize, usize)> {
            fn f((x, r): (usize, &Rule)) -> Option<(usize, usize, usize)> {
                match r.definitions.find_nested() {
                    Some((y, z)) => Some((x, y, z)),
                    _ => None,
                }
            }
            self.rules.iter().enumerate().filter_map(f).next()
        }
    }

    impl Display for Syntax {
        fn fmt(&self, f: &mut Formatter) -> fmt::Result {
            writeln!(f, "(E)BNF Syntax rules:")?;
            for rule in self.rules.iter() {
                writeln!(f, "{}", rule)?;
            }
            Ok(())
        }
    }

    impl Rule {
        pub fn new(name: &str, definitions: DefinitionList) -> Self {
            Rule {
                name: name.to_owned(),
                definitions,
            }
        }

        pub fn non_terminal(&self) -> Primary {
            Primary::NonTerminal(self.name.clone())
        }

        pub fn tokens(&self) -> Vec<EbnfToken> {
            let mut tokens = vec![EbnfToken::NonTerminal(&self.name), EbnfToken::Operator(Def)];

            tokens.append(&mut self.definitions.tokens());

            tokens
        }

        pub fn into_bnf(&self) -> Result<bnf::GrammarRule, ()> {
            let mut bnf = bnf::GrammarRule::new(&self.name);

            for definition in &self.definitions.0 {
                bnf.expression.push(definition.into_bnf()?);
            }

            Ok(bnf)
        }
    }

    impl Display for Rule {
        fn fmt(&self, f: &mut Formatter) -> fmt::Result {
            let mut tokens = self.tokens().into_iter();
            write!(f, "{}", tokens.next().unwrap().describe())?;
            for t in tokens {
                write!(f, " {}", t.describe())?;
            }
            Ok(())
        }
    }

    impl DefinitionList {
        pub fn tokens(&self) -> Vec<EbnfToken> {
            let mut tokens = vec![];

            let mut first = true;
            for d in &self.0 {
                if !first {
                    tokens.push(Operator(Alt));
                }
                first = false;

                tokens.append(&mut d.tokens())
            }

            tokens
        }

        /// Find next nearest nested term in the definition list, left-to-right.
        ///
        /// # Returns
        ///
        /// Index of definition in this `DefinitionList` AND index of `Primary` in that definition.
        pub fn find_nested(&self) -> Option<(usize, usize)> {
            fn f((y, d): (usize, &Definition)) -> Option<(usize, usize)> {
                match d.find_nested() {
                    Some(z) => Some((y, z)),
                    None => None,
                }
            }
            self.0.iter().enumerate().filter_map(f).next()
        }

        /// Using `is_empty` is slightly smarter that simple `len() == 0` test.
        pub fn is_empty(&self) -> bool {
            if self.len() == 0 {
                // no definitions at all
                true
            } else if self[0].len() == 0 {
                // one empty definition
                true
            } else if self[0][0] == Primary::Epsilon {
                // one definition with epsilon
                true
            } else {
                false
            }
        }
    }

    impl Deref for DefinitionList {
        type Target = Vec<Definition>;

        fn deref(&self) -> &Self::Target {
            &self.0
        }
    }

    impl DerefMut for DefinitionList {
        fn deref_mut(&mut self) -> &mut Self::Target {
            &mut self.0
        }
    }

    impl Definition {
        pub fn tokens(&self) -> Vec<EbnfToken> {
            let mut tokens = vec![];

            for p in &self.0 {
                tokens.append(&mut p.tokens());
            }

            tokens
        }

        fn find_nested(&self) -> Option<usize> {
            self.0.iter().position(Primary::is_nested)
        }

        pub fn into_bnf(&self) -> Result<Vec<bnf::GrammarSymbol>, ()> {
            let mut symbols = vec![];

            for primary in &self.0 {
                symbols.push(primary.into_bnf()?);
            }

            Ok(symbols)
        }
    }

    impl Deref for Definition {
        type Target = Vec<Primary>;

        fn deref(&self) -> &Self::Target {
            &self.0
        }
    }

    impl DerefMut for Definition {
        fn deref_mut(&mut self) -> &mut Self::Target {
            &mut self.0
        }
    }

    impl Primary {
        pub fn tokens(&self) -> Vec<EbnfToken> {
            let mut tokens = vec![];
            match *self {
                Primary::Optional(ref list) => {
                    tokens.push(Optional(Start));
                    tokens.append(&mut list.tokens());
                    tokens.push(Optional(End));
                }
                Primary::Repeated(ref list) => {
                    tokens.push(Repeat(Start));
                    tokens.append(&mut list.tokens());
                    tokens.push(Repeat(End));
                }
                Primary::Grouped(ref list) => {
                    tokens.push(Group(Start));
                    tokens.append(&mut list.tokens());
                    tokens.push(Group(End));
                }
                Primary::Terminal(ref t) => {
                    tokens.push(Terminal(&t));
                }
                Primary::NonTerminal(ref t) => {
                    tokens.push(NonTerminal(&t));
                }
                Primary::Epsilon => {}
            }
            tokens
        }
        pub fn is_nested(&self) -> bool {
            self.is_grouped() || self.is_repeated() || self.is_optional()
        }
        pub fn is_grouped(&self) -> bool {
            match self {
                Primary::Grouped(..) => true,
                _ => false,
            }
        }
        pub fn is_repeated(&self) -> bool {
            match self {
                Primary::Repeated(..) => true,
                _ => false,
            }
        }
        pub fn is_optional(&self) -> bool {
            match self {
                Primary::Optional(..) => true,
                _ => false,
            }
        }
        pub fn nesting(&self) -> Option<Nesting> {
            match self {
                Primary::Optional(..) => Some(Nesting::Optional),
                Primary::Repeated(..) => Some(Nesting::Repeated),
                Primary::Grouped(..) => Some(Nesting::Grouped),
                _ => None,
            }
        }
        pub fn into_inner(self) -> Option<DefinitionList> {
            match self {
                Primary::Optional(list) | Primary::Repeated(list) | Primary::Grouped(list) => {
                    Some(list)
                }
                _ => None,
            }
        }
        pub fn inner(&self) -> Option<&DefinitionList> {
            match self {
                Primary::Optional(ref list)
                | Primary::Repeated(ref list)
                | Primary::Grouped(ref list) => Some(list),
                _ => None,
            }
        }

        pub fn into_bnf(&self) -> Result<bnf::GrammarSymbol, ()> {
            match self {
                Primary::Optional(..) | Primary::Repeated(..) | Primary::Grouped(..) => Err(()),
                Primary::Terminal(ref t) => Ok(bnf::Terminal(t)),
                Primary::NonTerminal(ref t) => Ok(bnf::NonTerminal(t)),
                Primary::Epsilon => Ok(bnf::Terminal("")),
            }
        }
    }

    impl Nesting {
        fn expected(&self) -> &'static str {
            match *self {
                Nesting::Optional => "]",
                Nesting::Repeated => "}",
                Nesting::Grouped => ")",
            }
        }
    }

    impl<'a> Parser<'a> {
        fn new(source: &'a str, iter: EbnfTokens<'a>) -> Self {
            Parser {
                source,
                t: None,
                iter,
            }
        }

        pub fn parse(source: &'a str, filename: &'a str) -> Result<Syntax, ErrorBytes<'a>> {
            let mut syntax = Syntax::new();

            for line in non_empties(source.lines()) {
                let rule = Self::parse_rule(line)
                    .map_err(|e| ErrorBytes::from(e).source(source).filename(filename))?;
                syntax.rules.push(rule);
            }

            Ok(syntax)
        }

        pub fn parse_rule(source: &'a str) -> Result<Rule, SimpleErrorBytes> {
            let iter = make_lexer().tokens(source);
            let mut this = Parser::new(source, iter);

            let name = this.expect_non_terminal()?;
            this.expect_exact(Operator(Def))?;
            let definitions = this.parse_alternatives(None)?;

            Ok(Rule::new(name, definitions))
        }

        fn parse_alternatives(
            &mut self,
            nesting: Option<Nesting>,
        ) -> Result<DefinitionList, SimpleErrorBytes> {
            let mut definitions = vec![];
            let mut def = vec![];

            while let Some(Ok(meta)) = self.next() {
                match meta.token.clone() {
                    Terminal(t) => {
                        let terminal = if t == "" {
                            Primary::Epsilon
                        } else {
                            Primary::Terminal(t.to_owned())
                        };
                        def.push(terminal);
                    }
                    NonTerminal(t) => {
                        def.push(Primary::NonTerminal(t.to_owned()));
                    }
                    Operator(Alt) => {
                        definitions.push(Definition(def));
                        def = vec![];
                    }
                    Group(Start) => {
                        let list = self.parse_alternatives(Some(Nesting::Grouped))?;
                        def.push(Primary::Grouped(list));
                    }
                    Optional(Start) => {
                        let list = self.parse_alternatives(Some(Nesting::Optional))?;
                        def.push(Primary::Optional(list));
                    }
                    Repeat(Start) => {
                        let list = self.parse_alternatives(Some(Nesting::Repeated))?;
                        def.push(Primary::Repeated(list));
                    }
                    Group(End) if Some(Nesting::Grouped) == nesting => break,
                    Optional(End) if Some(Nesting::Optional) == nesting => break,
                    Repeat(End) if Some(Nesting::Repeated) == nesting => break,
                    Group(End) | Optional(End) | Repeat(End) => {
                        Err(match nesting {
                            Some(ref nesting) => self.error_expected(nesting.expected()),
                            None => self.error_expected(
                                "none of enclosing parenthesis at top level definition",
                            ),
                        })?;
                    }
                    Operator(Def) => {
                        Err(self.error_expected("anything but ::= operator"))?;
                    }
                }
            }
            definitions.push(Definition(def));
            match (self.current(), nesting) {
                (Some(Err(e)), _) => Err(e.clone().into()),
                (Some(Ok(..)), _) | (None, None) => {
                    // no more tokens nor nesting
                    Ok(DefinitionList(definitions))
                }
                // no more tokens but nested groups left opened.
                (None, Some(ref nesting)) => Err(self.error_expected(nesting.expected())),
            }
        }

        fn current(&self) -> Option<MetaResult<'a, EbnfToken<'a>>> {
            self.t.clone()
        }

        fn next(&mut self) -> Option<MetaResult<'a, EbnfToken<'a>>> {
            let result = self.iter.next();
            self.t = result;
            self.current()
        }

        fn expect_non_terminal(&mut self) -> Result<&'a str, SimpleErrorBytes> {
            match self.next() {
                Some(Ok(TokenMeta {
                    token: NonTerminal(t),
                    ..
                })) => Ok(t),
                _ => Err(self.error_expected("non-terminal.")),
            }
        }

        fn expect_exact(&mut self, tok: EbnfToken<'a>) -> Result<(), SimpleErrorBytes> {
            match self.next() {
                Some(Ok(TokenMeta { token, .. })) if tok == token => Ok(()),
                _ => Err(self.error_expected(tok.descriptor())),
            }
        }

        fn error_expected(&self, expectation: &str) -> SimpleErrorBytes {
            let description = format!("Expected {}.", expectation);
            match self.current() {
                Some(Ok(meta)) => Into::<SimpleErrorBytes>::into(meta.clone()),
                Some(Err(e)) => Into::<SimpleErrorBytes>::into(e.clone()),
                None => {
                    let span = self
                        .current()
                        .clone()
                        .and_then(|x| x.ok())
                        .map(|t| t.span)
                        .or_else(|| Span::over(self.source))
                        .unwrap_or_default();
                    SimpleErrorBytes {
                        span,
                        description: None,
                    }
                }
            }.description(Some(description))
        }
    }
}

#[cfg(test)]
mod tests {
    #![allow(non_snake_case)]

    use super::*;
    use lex::Error;

    const FILENAME: &str = "<test.bnf>";

    #[test]
    fn test_parse_expectation() {
        let source = r#"??? ::= <A> "B" <C>"#;
        let result = Parser::parse_rule(source);
        assert!(result.is_err());
        // println!("{:?}", result.err().unwrap())
    }

    #[test]
    fn test_parse_empty() {
        let source = " ";
        let res = Parser::parse_rule(source);
        assert!(res.is_err());

        let err = res.err().unwrap();
        let err: Error<_> = err.into();
        let err = err.source(source).filename(FILENAME);
        // println!("AAAAAAA: {:?}", err);
        // println!("AAAAAAA:\n{}", err);
        let _ = err;
    }

    #[test]
    fn test_parse_no_def() {
        let source = "<A> <AC/DC> <EFG> ::= \"123\" ";
        let res = Parser::parse_rule(source);
        assert!(res.is_err());

        let err: Error<_> = res.err().unwrap().into();
        let err = err.source(source).filename(FILENAME);
        // println!("AAA\n{:?}", err);
        // println!("AAA\n{}", err);
        let _ = err;
    }

    #[test]
    fn test_parse_epsilon() {
        let source = "<A> ::= ";
        let res = Parser::parse_rule(source);
        assert!(res.is_ok());

        let rule = res.unwrap();
        assert_eq!("A", rule.name);
        assert_eq!(rule.definitions.0, [Definition(vec![])]);
    }

    #[test]
    fn test_parse_simple_product() {
        let source = r#" <A> ::= <B> "C" "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_ok());

        let rule = res.unwrap();
        assert_eq!("A", rule.name);
        assert_eq!(
            rule.definitions.0,
            [Definition(vec![
                Primary::NonTerminal("B".into()),
                Primary::Terminal("C".into())
            ])]
        );
    }

    #[test]
    fn test_parse_alternatives() {
        let source = r#" <A> ::= <B> | "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_ok());

        let rule = res.unwrap();
        assert_eq!(rule.name, "A");
        assert_eq!(
            rule.definitions.0,
            [
                Definition(vec![Primary::NonTerminal("B".into())]),
                Definition(vec![])
            ]
        );
    }

    #[test]
    fn test_parse_group() {
        let source = r#" <A> ::= <B> ("c" | <D> <E> | "f") | "g" "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_ok());

        let rule = res.unwrap();
        assert_eq!(rule.name, "A");
        assert_eq!(
            rule.definitions.0,
            [
                Definition(vec![
                    Primary::NonTerminal("B".into()),
                    Primary::Grouped(DefinitionList(vec![
                        Definition(vec![Primary::Terminal("c".into())]),
                        Definition(vec![
                            Primary::NonTerminal("D".into()),
                            Primary::NonTerminal("E".into())
                        ]),
                        Definition(vec![Primary::Terminal("f".into())])
                    ]))
                ]),
                Definition(vec![Primary::Terminal("g".into())])
            ]
        );
    }

    #[test]
    fn test_parse_group_unclosed() {
        let source = r#" <A> ::= <B> ( "c" | "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_err());

        let source = r#" <A> ::= <B> [ "c" | "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_err());

        let source = r#" <A> ::= <B> { "c" | "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_err());
    }

    #[test]
    fn test_parse_unexpected_close() {
        let source = r#" <A> ::= ) "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_err());
        // println!("EEE {:?}", res);
    }

    #[test]
    fn test_parse_unexpected_close_another() {
        let source = r#" <A> ::= { [ "b" } "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_err());
        // println!("EEE {:?}", res);
    }

    #[test]
    fn test_parse_deep_nesting() {
        let source = r#" <A> ::= { "b" ([<C>] <D> | "e" {"e"} ) } "#;
        let res = Parser::parse_rule(source);
        assert!(res.is_ok());
    }

    /// # Syntax
    #[test]
    fn test_whole_syntax() {
        let source = r#"
            <A> ::= "d" [ <B> ]
            <B> ::= "c" <A> | <D>

            <D> ::= "e" { "f" <A> }
        "#;
        let res = Parser::parse(source, FILENAME);
        assert!(res.is_ok());

        let syntax = res.unwrap();
        assert_eq!(
            syntax.rules,
            vec![
                Rule::new(
                    "A",
                    DefinitionList(vec![Definition(vec![
                        Primary::Terminal("d".into()),
                        Primary::Optional(DefinitionList(vec![Definition(vec![
                            Primary::NonTerminal("B".into())
                        ])]))
                    ])]),
                ),
                Rule::new(
                    "B",
                    DefinitionList(vec![
                        Definition(vec![
                            Primary::Terminal("c".into()),
                            Primary::NonTerminal("A".into())
                        ]),
                        Definition(vec![Primary::NonTerminal("D".into())])
                    ]),
                ),
                Rule::new(
                    "D",
                    DefinitionList(vec![Definition(vec![
                        Primary::Terminal("e".into()),
                        Primary::Repeated(DefinitionList(vec![Definition(vec![
                            Primary::Terminal("f".into()),
                            Primary::NonTerminal("A".into()),
                        ])]))
                    ])]),
                )
            ]
        );
    }

    fn bnf(source: &str, recursion: Recursion) -> Syntax {
        let mut syntax = Parser::parse(source, FILENAME).unwrap();
        syntax.expand_ebnf(recursion);
        syntax
    }

    #[test]
    fn test_ebnf_optional_empty() {
        let source = r#" <X> ::= [] "A" [] "B" [] "#;
        let syntax = bnf(source, Recursion::Left);

        assert_eq!(syntax.rules.len(), 1);
        assert_eq!(
            syntax.rules[0],
            bnf(r#" <X> ::= "A" "B" "#, Recursion::Left).rules[0]
        );
    }

    #[test]
    fn test_ebnf_optional_single() {
        let source = r#" <X> ::= "A" ["E"] "B" "#;
        let syntax = bnf(source, Recursion::Left);

        assert_eq!(syntax.rules.len(), 1);
        assert_eq!(
            syntax.rules[0],
            Rule::new(
                "X",
                DefinitionList(vec![
                    // "A" "E" "B"
                    Definition(vec![
                        Primary::Terminal("A".into()),
                        Primary::Terminal("E".into()),
                        Primary::Terminal("B".into())
                    ]),
                    // "A" "B"
                    Definition(vec![
                        Primary::Terminal("A".into()),
                        Primary::Terminal("B".into())
                    ]),
                ])
            )
        );
    }

    #[test]
    fn test_ebnf_optional_multi() {
        let source = r#" <X> ::= "A" ["E" | "F"] "B" "#;
        let syntax = bnf(source, Recursion::Left);

        let X0 = syntax.autogenerated_names_registry[0].clone();

        let rule_X = Rule::new(
            "X",
            DefinitionList(vec![Definition(vec![
                Primary::Terminal("A".into()),
                Primary::NonTerminal(X0.clone()),
                Primary::Terminal("B".into()),
            ])]),
        );
        let rule_X0 = Rule::new(
            &X0,
            DefinitionList(vec![
                Definition(vec![Primary::Epsilon]),
                Definition(vec![Primary::Terminal("E".into())]),
                Definition(vec![Primary::Terminal("F".into())]),
            ]),
        );

        assert_eq!(syntax.rules, [rule_X, rule_X0]);
    }

    #[test]
    fn test_ebnf_repeated_single_left() {
        let source = r#" <A> ::= { "E" } "#;
        let syntax = bnf(source, Recursion::Left);

        assert_eq!(syntax.rules.len(), 2);

        let name = syntax.autogenerated_names_registry[0].clone();
        let X = Primary::NonTerminal(name.clone());
        assert_eq!(
            syntax.rules,
            [
                // <A> ::= <X>
                Rule::new("A", DefinitionList(vec![Definition(vec![X.clone()])])),
                // <X> ::= "" | <X> ( "E" )
                Rule::new(
                    &name,
                    DefinitionList(vec![
                        // ""
                        Definition(vec![Primary::Epsilon]),
                        // <X> "E"
                        Definition(vec![X.clone(), Primary::Terminal("E".into())])
                    ])
                )
            ]
        );
    }

    #[test]
    fn test_ebnf_repeated_single_right() {
        let source = r#" <A> ::= { "E" } "#;
        let syntax = bnf(source, Recursion::Right);

        assert_eq!(syntax.rules.len(), 2);

        let name = syntax.autogenerated_names_registry[0].clone();
        let X = Primary::NonTerminal(name.clone());
        assert_eq!(
            syntax.rules,
            [
                // <A> ::= <X>
                Rule::new("A", DefinitionList(vec![Definition(vec![X.clone()])])),
                // <X> ::= "" | ( "E" ) <X>
                Rule::new(
                    &name,
                    DefinitionList(vec![
                        // ""
                        Definition(vec![Primary::Epsilon]),
                        // "E" <X>
                        Definition(vec![Primary::Terminal("E".into()), X.clone()])
                    ])
                )
            ]
        );
    }

    #[test]
    fn test_ebnf_repeated_needs_group() {
        let source = r#" <A> ::= "C" { "E" | "F" } "D" "#;
        let syntax = bnf(source, Recursion::Left);

        //(E)BNF Syntax rules:
        //<A> ::= "C" <X-auto-0> "D"
        //<X-auto-0> ::= | <X-auto-0> <X-auto-1>
        //<X-auto-1> ::= "E" | "F"

        assert_eq!(syntax.rules.len(), 3);

        let X0 = syntax.autogenerated_names_registry[0].clone();
        let X1 = syntax.autogenerated_names_registry[1].clone();
        let rule_A = Rule::new(
            "A",
            DefinitionList(vec![Definition(vec![
                Primary::Terminal("C".into()),
                Primary::NonTerminal(X0.clone()),
                Primary::Terminal("D".into()),
            ])]),
        );
        let rule_X0 = Rule::new(
            &X0,
            DefinitionList(vec![
                Definition(vec![Primary::Epsilon]),
                Definition(vec![
                    Primary::NonTerminal(X0.clone()),
                    Primary::NonTerminal(X1.clone()),
                ]),
            ]),
        );
        let rule_X1 = Rule::new(
            &X1,
            DefinitionList(vec![
                Definition(vec![Primary::Terminal("E".into())]),
                Definition(vec![Primary::Terminal("F".into())]),
            ]),
        );

        assert_eq!(syntax.rules, [rule_A, rule_X0, rule_X1]);
    }

    #[test]
    fn test_ebnf_grouped_empty() {
        let source = r#" <X> ::= "A" ( ) "B" "#;
        let syntax = bnf(source, Recursion::Left);

        // expected: <X> ::= "A" "B"
        assert_eq!(
            syntax.rules,
            [Rule::new(
                "X",
                DefinitionList(vec![Definition(vec![
                    Primary::Terminal("A".into()),
                    Primary::Terminal("B".into()),
                ])])
            )]
        );
    }

    #[test]
    fn test_ebnf_grouped_single() {
        let source = r#" <A> ::= ( "E" ) "#;
        let syntax = bnf(source, Recursion::Left);

        assert_eq!(syntax.rules.len(), 2);
        let X = syntax.autogenerated_names_registry[0].clone();

        assert_eq!(
            syntax.rules,
            [
                Rule::new(
                    "A",
                    DefinitionList(vec![Definition(vec![Primary::NonTerminal(X.clone())])])
                ),
                Rule::new(
                    &X,
                    DefinitionList(vec![Definition(vec![Primary::Terminal("E".into())])])
                ),
            ]
        );
    }

    #[test]
    fn test_ebnf_grouped_multi() {
        let source = r#" <R> ::= "A" | ( "E" | "F" ) "B" | "C" "#;
        let syntax = bnf(source, Recursion::Left);

        assert_eq!(syntax.rules.len(), 2);
        let X = syntax.autogenerated_names_registry[0].clone();

        assert_eq!(
            syntax.rules,
            [
                Rule::new(
                    "R",
                    DefinitionList(vec![
                        Definition(vec![Primary::Terminal("A".into())]),
                        Definition(vec![
                            Primary::NonTerminal(X.clone()),
                            Primary::Terminal("B".into())
                        ]),
                        Definition(vec![Primary::Terminal("C".into())]),
                    ])
                ),
                Rule::new(
                    &X,
                    DefinitionList(vec![
                        Definition(vec![Primary::Terminal("E".into())]),
                        Definition(vec![Primary::Terminal("F".into())]),
                    ])
                ),
            ]
        );
    }
}
